<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <title>perform_detection</title>
        <style type="text/css">
          .end-element { fill : #FFCCFF; }
        </style>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.3.0/raphael.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.17.1/flowchart.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.3.1/js/bootstrap.bundle.min.js"></script>
        <!-- <script src="../release/flowchart.min.js"></script> -->
        <script>

            window.onload = function () {
                var btn = document.getElementById("run"),
                    cd = document.getElementById("code"),
                    chart;
                    
                (btn.onclick = function () {
                    var code = cd.value;

                    if (chart) {
                      chart.clean();
                    }

                    chart = flowchart.parse(code);
                    chart.drawSVG('canvas', {
                      'x': 0,
                      'y': 0,
                      'line-width': 3,
                      //'maxWidth': 15,//ensures the flowcharts fits within a certain width
                      'line-length': 50,
                      'text-margin': 10,
                      'font-size': 14,
                      'font': 'normal',
                      'font-family': 'Helvetica',
                      'font-weight': 'normal',
                      'font-color': 'black',
                      'line-color': 'black',
                      'element-color': 'black',
                      'fill': 'white',
                      'yes-text': 'yes',
                      'no-text': 'no',
                      'arrow-end': 'block',
                      'scale': 1,
                      'symbols': {
                        'start': {
                          'font-size': 14,
                          'font-color': 'yellow',
                          'element-color': 'blue',
                          'fill': 'green',
                          'class': 'start-element'
                        },
                        'inputoutput': {
                          'font-color': 'black',
                          'element-color': 'black',
                          'fill': 'bisque'
                        },
                        'operation': {
                          'font-color': 'black',
                          'element-color': 'black',
                          'fill': 'linen'
                        },
                        'subroutine': {
                          'font-color': 'black',
                          'element-color': 'blue',
                          'fill': 'lightgreen'
                        },
                        'condition': {
                          'font-color': 'red',
                          'element-color': 'black',
                          'fill': 'yellow'
                        },
                        'end':{
                          'font-size': 20,
                          'class': 'end-element'
                        }
                      },
                      'flowstate' : {
                        //'past' : { 'fill' : '#CCCCCC', 'font-size' : 12},
                        //'current' : {'fill' : 'yellow', 'font-color' : 'red', 'font-weight' : 'bold'},
                        //'future' : { 'fill' : '#FFFF99'},
                        'request' : { 'fill' : 'blue'},
                        'invalid': {'fill' : '#444444'},
                        'approved' : { 'fill' : '#58C4A3', 'font-size' : 12, 'yes-text' : 'APPROVED', 'no-text' : 'n/a' },
                        'rejected' : { 'fill' : '#C45879', 'font-size' : 12, 'yes-text' : 'n/a', 'no-text' : 'REJECTED' }
                      }
                    });
                    //create base64 encoding of SVG to generate download link for title(without html or htm).SVG
                    var currentCanvasDIV = document.getElementById('canvas')
                    var currentDrawSVG = currentCanvasDIV.innerHTML.replaceAll('ë','e');

                    const OUTsvgBASE64 = btoa(currentDrawSVG)
                    doctitle = document.title.replace('.html','');
                    doctitle = doctitle.replace('.htm','');


                    var currentCanvasDIV = document.getElementById('canvas')
                    var currentDrawSVG = currentCanvasDIV.innerHTML.replaceAll('ë','e');
                    svgSource = currentDrawSVG
                    svgXML = currentDrawSVG;
                    // Use SVG Height and Width from the SVG XML to set canvas size
                    svgXMLsubstringHeight = svgXML.substring(svgXML.indexOf('height='), svgXML.indexOf('version='));
                    svgXMLsubstringWidth = svgXML.substring(svgXML.indexOf('width='), svgXML.indexOf('xmlns='));
                    HeightValue = svgXMLsubstringHeight.substring(svgXMLsubstringHeight.indexOf('"')+1,svgXMLsubstringHeight.lastIndexOf('"'));
                    WidthValue = svgXMLsubstringWidth.substring(svgXMLsubstringWidth.indexOf('"')+1,svgXMLsubstringWidth.lastIndexOf('"'));
                    HeightValueInt = Math.round(HeightValue)
                    WidthValueInt = Math.round(WidthValue)
                    // setup input for base64SvgToBase64Png
                    let svgSrc = "data:image/svg+xml;base64,"+OUTsvgBASE64;
                    var pngBase
                    imageUtil.base64SvgToBase64Png(svgSrc, WidthValueInt, HeightValueInt).then(pngSrc => {
                    pngBase = pngSrc
                    // output download link for base64 PNG converted on download from base64
                    var pngOutHtml = `<a href="${pngBase}" download="${doctitle}.png">PNG - Click here to download current rendered flowchart as ${doctitle}.png</a>`
                    document.getElementById("pngbase64").innerHTML=pngOutHtml;
                    });    
                    // output download link for base64 SVG converted on download from base64
                    var svgOutHtml = `<a href="data:image/svg+xml;base64,${OUTsvgBASE64}" download=${doctitle}.svg>SVG - Click here to download current rendered flowchart as ${doctitle}.svg</a> `
                        document.getElementById("svgbase64").innerHTML=svgOutHtml;
                    })();

                            };
                 

// derived from https://stackoverflow.com/a/64800570
// we need to use web browser canvas to generate a image. In this case png
let imageUtil = {};
/**
 * converts a base64 encoded data url SVG image to a PNG image
 * @param originalBase64 data url of svg image
 * @param width target width in pixel of PNG image
 * @param secondTry used internally to prevent endless recursion
 * @return {Promise<unknown>} resolves to png data url of the image
 */
imageUtil.base64SvgToBase64Png = function (originalBase64, width, height, secondTry) {
    return new Promise(resolve => {
        let img = document.createElement('img');
        img.onload = function () {
            if (!secondTry && (img.naturalWidth === 0 || img.naturalHeight === 0)) {
                let svgDoc = base64ToSvgDocument(originalBase64);
                let fixedDoc = fixSvgDocumentFF(svgDoc);
                return imageUtil.base64SvgToBase64Png(svgDocumentToBase64(fixedDoc), width, height, true).then(result => {
                    resolve(result);
                });
            }
            //document.body.appendChild(img);
            let canvas2 = document.createElement("canvas");
            //document.body.removeChild(img);
            canvas2.width = width;
            canvas2.height = height;
            let ctx = canvas2.getContext("2d");
            ctx.drawImage(img, 0, 0, canvas2.width, canvas2.height);
            try {
                let data = canvas2.toDataURL('image/png');
                resolve(data);
            } catch (e) {
                resolve(null);
            }
        };
        img.src = originalBase64;
    });
}

//needed because Firefox doesn't correctly handle SVG with size = 0, see https://bugzilla.mozilla.org/show_bug.cgi?id=700533
function fixSvgDocumentFF(svgDocument) {
    try {
        let widthInt = parseInt(svgDocument.documentElement.width.baseVal.value) || 500;
        let heightInt = parseInt(svgDocument.documentElement.height.baseVal.value) || 500;
        svgDocument.documentElement.width.baseVal.newValueSpecifiedUnits(SVGLength.SVG_LENGTHTYPE_PX, widthInt);
        svgDocument.documentElement.height.baseVal.newValueSpecifiedUnits(SVGLength.SVG_LENGTHTYPE_PX, heightInt);
        return svgDocument;
    } catch (e) {
        return svgDocument;
    }
}

function svgDocumentToBase64(svgDocument) {
    try {
        let base64EncodedSVG = btoa(new XMLSerializer().serializeToString(svgDocument));
        return 'data:image/svg+xml;base64,' + base64EncodedSVG;
    } catch (e) {
        return null;
    }
}

function base64ToSvgDocument(base64) {
    let svg = atob(base64.substring(base64.indexOf('base64,') + 7));
    svg = svg.substring(svg.indexOf('<svg'));
    let parser = new DOMParser();
    return parser.parseFromString(svg, "image/svg+xml");
} 
        </script>

        <script>
            function HelpText() {
              var x = document.getElementById("HelpTextBlock");
              if (x.style.display === "none") {
                x.style.display = "block";
              } else {
                x.style.display = "none";
              }
            }
        </script>
    </head>
    <body>
        <div><textarea id="code" style="width: 100%;" rows="11">st3=>start: start perform_detection
io5=>inputoutput: input: args, net, val_data_loader, val_dataset, iteration
op8=>operation: '\n    Perform detection on a video database using a trained network.\n\n    This function runs the detection process on a validation dataset,\n    processes the results, and evaluates the performance.\n\n    Parameters:\n    args (object): object containing various arguments and configurations for the detection process.\n    net (nn.Module): The neural network model used for detection.\n    val_data_loader (DataLoader): DataLoader for the validation dataset.\n    val_dataset (Dataset): The validation dataset.\n    iteration (int): The current iteration or epoch number.\n\n    Returns:\n    tuple: A tuple containing three elements:\n        - list: Combined mean Average Precision (mAP) values for object detection and ego action recognition.\n        - list: Combined Average Precision (AP) values for all classes in object detection and ego action recognition.\n        - list: Combined strings describing AP for each class in object detection and ego action recognition.\n    '
op10=>operation: 'Test a network on a video database.'
op12=>operation: num_images = len(val_dataset)
op14=>operation: print_time = True
op16=>operation: val_step = 50
op18=>operation: count = 0
sub20=>subroutine: torch.cuda.synchronize()
op22=>operation: ts = time.perf_counter()
op24=>operation: activation = torch.nn.Sigmoid().cuda()
op26=>operation: ego_pds = []
op28=>operation: ego_gts = []
op30=>operation: det_boxes = []
op32=>operation: gt_boxes_all = []
cond35=>condition: for nlt in range(1)
op46=>operation: numc = args.num_classes_list[nlt]
sub48=>subroutine: det_boxes.append([[] for _ in range(numc)])
sub50=>subroutine: gt_boxes_all.append([])
op54=>operation: nlt = 0
op56=>operation: processed_videos = []
op58=>operation: with torch.no_grad():
    for (val_itr, (images, gt_boxes, gt_targets, ego_labels, batch_counts, img_indexs, wh)) in enumerate(val_data_loader):
        torch.cuda.synchronize()
        t1 = time.perf_counter()
        batch_size = images.size(0)
        images = images.cuda(0, non_blocking=True)
        (decoded_boxes, confidence, ego_preds) = net(images)
        ego_preds = activation(ego_preds).cpu().numpy()
        ego_labels = ego_labels.numpy()
        confidence = activation(confidence)
        seq_len = ego_preds.shape[1]
        if (val_itr == 5):
            os.system('nvidia-smi')
        if (print_time and ((val_itr % val_step) == 0)):
            torch.cuda.synchronize()
            tf = time.perf_counter()
            logger.info('Forward Time {:0.3f}'.format((tf - t1)))
        for b in range(batch_size):
            index = img_indexs[b]
            annot_info = val_dataset.ids[index]
            if (args.DATASET != 'ava'):
                (video_id, frame_num, step_size) = annot_info
            else:
                (video_id, frame_num, step_size, keyframe) = annot_info
                startf = frame_num
                temp_startf = frame_num
                frame_num = (keyframe - 1)
            videoname = val_dataset.video_list[video_id]
            save_dir = '{:s}/{}'.format(args.det_save_dir, videoname)
            store_last = False
            if (videoname not in processed_videos):
                processed_videos.append(videoname)
                store_last = True
            if (not os.path.isdir(save_dir)):
                os.makedirs(save_dir)
            count += 1
            for si in range(seq_len):
                if ((args.DATASET == 'ava') and (startf != keyframe)):
                    startf += step_size
                    continue
                if (ego_labels[(b, si)] > (- 1)):
                    ego_pds.append(ego_preds[b, si, :])
                    ego_gts.append(ego_labels[(b, si)])
                gt_boxes_batch = gt_boxes[b, si, :batch_counts[(b, si)], :].numpy()
                gt_labels_batch = gt_targets[b, si, :batch_counts[(b, si)]].numpy()
                decoded_boxes_batch = decoded_boxes[(b, si)]
                frame_gt = utils.get_individual_labels(gt_boxes_batch, gt_labels_batch[:, :1])
                gt_boxes_all[0].append(frame_gt)
                confidence_batch = confidence[(b, si)]
                scores = confidence_batch[:, 0].squeeze().clone()
                (cls_dets, save_data) = utils.filter_detections_for_dumping(args, scores, decoded_boxes_batch, confidence_batch)
                det_boxes[0][0].append(cls_dets)
                save_name = '{:s}/{:05d}.pkl'.format(save_dir, (frame_num + 1))
                frame_num += step_size
                save_data = {'ego': ego_preds[b, si, :], 'main': save_data, 'cls_dets': cls_dets}
                if ((si < (seq_len - args.skip_ending)) or store_last):
                    with open(save_name, 'wb') as ff:
                        pickle.dump(save_data, ff)
                if (args.DATASET == 'ava'):
                    startf += step_size
        if (print_time and ((val_itr % val_step) == 0)):
            torch.cuda.synchronize()
            te = time.perf_counter()
            logger.info('im_detect: {:d}/{:d} time taken {:0.3f}'.format(count, num_images, (te - ts)))
            torch.cuda.synchronize()
            ts = time.perf_counter()
        if (print_time and ((val_itr % val_step) == 0)):
            torch.cuda.synchronize()
            te = time.perf_counter()
            logger.info('NMS stuff Time {:0.3f}'.format((te - tf)))
op60=>operation: (mAP, ap_all, ap_strs) = evaluate.evaluate(gt_boxes_all, det_boxes, args.all_classes, iou_thresh=args.IOU_THRESH)
op62=>operation: (mAP_ego, ap_all_ego, ap_strs_ego) = evaluate.evaluate_ego(np.asarray(ego_gts), np.asarray(ego_pds), args.ego_classes)
io67=>inputoutput: output:  ((mAP + [mAP_ego]), (ap_all + [ap_all_ego]), (ap_strs + [ap_strs_ego]))
e65=>end: end function return

st3->io5
io5->op8
op8->op10
op10->op12
op12->op14
op14->op16
op16->op18
op18->sub20
sub20->op22
op22->op24
op24->op26
op26->op28
op28->op30
op30->op32
op32->cond35
cond35(yes)->op46
op46->sub48
sub48->sub50
sub50(left)->cond35
cond35(no)->op54
op54->op56
op56->op58
op58->op60
op60->op62
op62->io67
io67->e65
</textarea></div>
        <div><button id="run" type="button">Run</button> <button onclick="HelpText()">Format Help</button></div>
        <div id="HelpTextBlock" style="display:none"><br/>Conditions can also be redirected like cond(yes, bottom) or cond(yes, right)
... and the other symbols too... like sub1(right)<br/>
You can also tweak the <b>diagram.drawSVG('diagram', {});</b> script in this file for more changes<br/>
This is based on <a href="https://github.com/adrai/flowchart.js">flowchart.js on github</a> and <a href="http://flowchart.js.org">http://flowchart.js.org</a> more documentation can be found over there.
</div><br/><div id="svgbase64"></div>
        <div id="pngbase64"></div>

        <div id="canvas"></div>
    </body>
</html>